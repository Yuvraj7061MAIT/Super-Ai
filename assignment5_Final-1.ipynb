{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd3K0Q3xKtoh",
        "outputId": "5ddab7d0-172c-40aa-a191-6e64999b209e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas scikit-learn nltk tensorflow transformers torch textblob gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "mJMRKOh2K9Dp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ6F0l8xQ2DL",
        "outputId": "74abc21a-7508-43ba-d643-c856d409d26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "lYufSRaPRNa5"
      },
      "outputs": [],
      "source": [
        "# Sample Data\n",
        "data = {\n",
        "    'prompt': [\n",
        "        \"Create a chatbot script for customer support\",\n",
        "        \"Generate a response for mental health chat\",\n",
        "        \"Write a conversation starter for virtual assistants\",\n",
        "        \"Generate an image of a sunset over the ocean\",\n",
        "        \"Create a video clip of a relaxing forest scene\",\n",
        "        \"Develop a conversational flow for a virtual assistant handling scheduling\",\n",
        "        \"Generate a supportive message for someone experiencing anxiety\",\n",
        "        \"Write an introduction script for a virtual tour guide\",\n",
        "        \"Create a realistic image of a mountain landscape\",\n",
        "        \"Produce a short video of a cityscape at night\",\n",
        "        \"Compose a background score for a meditation session\",\n",
        "        \"Generate a speech script for a company announcement\",\n",
        "        \"Create podcast episode outlines about technology trends\",\n",
        "        \"Write a blog post on the benefits of remote work\",\n",
        "        \"Generate a podcast script discussing climate change\",\n",
        "        \"Develop a story outline for a children's adventure book\",\n",
        "        \"Create social media posts for a new product launch\",\n",
        "        \"Write product descriptions for an online store\",\n",
        "        \"Optimize a website's content for search engines\",\n",
        "        \"Generate a market analysis report for a new app\",\n",
        "        \"Translate a document from English to Spanish\",\n",
        "        \"Provide coding assistance for a Python project\",\n",
        "        \"Integrate a third-party API into a web application\",\n",
        "        \"Analyze sales data and generate a report\",\n",
        "        \"Create a financial report based on quarterly earnings\",\n",
        "        \"Develop educational content for an online course\",\n",
        "        \"Assist in learning Spanish vocabulary\",\n",
        "        \"Create a PowerPoint presentation on digital marketing\",\n",
        "        \"Generate email templates for business communication\",\n",
        "        \"Draft a legal document for a lease agreement\",\n",
        "        \"Generate a contract for freelance work\",\n",
        "        \"Create a healthy meal plan for a week\",\n",
        "        \"Generate a fitness routine for beginners\",\n",
        "        \"Solve math homework problems\",\n",
        "        \"Detect AI-generated content in student essays\",\n",
        "        \"Design a logo for a startup company\",\n",
        "        \"Create a branding strategy for a new brand\",\n",
        "        \"Plan a travel itinerary for a trip to Europe\",\n",
        "        \"Organize an event plan for a wedding\",\n",
        "        \"Write detailed product descriptions for an online shop\",\n",
        "        \"Generate personalized product recommendations\",\n",
        "        \"Draft a resume for a job application\",\n",
        "        \"Write a cover letter for a software developer position\",\n",
        "        \"Summarize data for a research paper\",\n",
        "        \"Generate a summary of the latest news articles\",\n",
        "        \"Create a news article about a recent scientific discovery\",\n",
        "        \"Generate a route for an LLM handling diverse queries\"\n",
        "    ],\n",
        "    'category': [\n",
        "        \"Communication\",\n",
        "        \"Communication\",\n",
        "        \"Communication\",\n",
        "        \"Visual Art\",\n",
        "        \"Visual Art\",\n",
        "        \"Communication\",\n",
        "        \"Communication\",\n",
        "        \"Communication\",\n",
        "        \"Visual Art\",\n",
        "        \"Visual Art\",\n",
        "        \"Music and Audio\",\n",
        "        \"Music and Audio\",\n",
        "        \"Music and Audio\",\n",
        "        \"Writing and Content Creation\",\n",
        "        \"Writing and Content Creation\",\n",
        "        \"Writing and Content Creation\",\n",
        "        \"Marketing and Advertising\",\n",
        "        \"Marketing and Advertising\",\n",
        "        \"Marketing and Advertising\",\n",
        "        \"Marketing and Advertising\",\n",
        "        \"Translation and Localization\",\n",
        "        \"Programming and Development\",\n",
        "        \"Programming and Development\",\n",
        "        \"Data and Analytics\",\n",
        "        \"Data and Analytics\",\n",
        "        \"Education and Training\",\n",
        "        \"Education and Training\",\n",
        "        \"Business and Productivity\",\n",
        "        \"Business and Productivity\",\n",
        "        \"Legal and Professional Services\",\n",
        "        \"Legal and Professional Services\",\n",
        "        \"Health and Wellness\",\n",
        "        \"Health and Wellness\",\n",
        "        \"Homework\",\n",
        "        \"Homework\",\n",
        "        \"Design\",\n",
        "        \"Design\",\n",
        "        \"Travel and Hospitality\",\n",
        "        \"Travel and Hospitality\",\n",
        "        \"Retail and E-commerce\",\n",
        "        \"Retail and E-commerce\",\n",
        "        \"Human Resources\",\n",
        "        \"Human Resources\",\n",
        "        \"Science and Research\",\n",
        "        \"Science and Research\",\n",
        "        \"Media and Journalism\",\n",
        "        \"Others\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Jn1Tma9eRQFf"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "yZKNc02GRR1O"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = simple_preprocess(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['cleaned_prompt'] = df['prompt'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "BhRAnuy8RTMe"
      },
      "outputs": [],
      "source": [
        "# Tokenization and Vectorization\n",
        "# BoW and TF-IDF\n",
        "bow_vectorizer = CountVectorizer()\n",
        "tfidf_vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "jGqWxnjbRUxP"
      },
      "outputs": [],
      "source": [
        "X_bow = bow_vectorizer.fit_transform(df['cleaned_prompt'])\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_prompt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "0VRC0VBERWE5"
      },
      "outputs": [],
      "source": [
        "# Word2Vec Embedding\n",
        "sentences = [simple_preprocess(text) for text in df['prompt']]\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "kA65GGClRXcH"
      },
      "outputs": [],
      "source": [
        "def get_word2vec_features(text):\n",
        "    tokens = simple_preprocess(text)\n",
        "    feature_vec = np.zeros(100)\n",
        "    count = 0\n",
        "    for word in tokens:\n",
        "        if word in word2vec_model.wv:\n",
        "            feature_vec += word2vec_model.wv[word]\n",
        "            count += 1\n",
        "    if count > 0:\n",
        "        feature_vec /= count\n",
        "    return feature_vec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "DpZwY-fJRZIl"
      },
      "outputs": [],
      "source": [
        "X_word2vec = np.array([get_word2vec_features(text) for text in df['prompt']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "RXoEKnsSRaY2"
      },
      "outputs": [],
      "source": [
        "# Encode Labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['label'] = label_encoder.fit_transform(df['category'])\n",
        "num_classes = len(label_encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "10FUs1WkRd1P"
      },
      "outputs": [],
      "source": [
        "# Split data into train and test sets\n",
        "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X_bow, df['label'], test_size=0.2, random_state=42)\n",
        "X_train_tfidf, X_test_tfidf, _, _ = train_test_split(X_tfidf, df['label'], test_size=0.2, random_state=42)\n",
        "X_train_word2vec, X_test_word2vec, _, _ = train_test_split(X_word2vec, df['label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "vtWawAOwRecO"
      },
      "outputs": [],
      "source": [
        "# Define RNN Models with LSTM and GRU\n",
        "def create_rnn_model(vocab_size, embedding_dim, input_length):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_dim, input_length=input_length))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(128))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "qtMzCJCURjSx"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_gru_model(vocab_size, embedding_dim, input_length):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_dim, input_length=input_length))\n",
        "    model.add(GRU(128, return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(GRU(128))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "VO34_spLRlZF"
      },
      "outputs": [],
      "source": [
        "# Prepare Data for RNN\n",
        "input_length = X_train_bow.shape[1]\n",
        "embedding_dim = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxPKyUccRoSc",
        "outputId": "26c34b30-1434-4784-f332-cf190b44c3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_lstm = create_rnn_model(input_length, embedding_dim, input_length)\n",
        "model_gru = create_gru_model(input_length, embedding_dim, input_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "5-6a56DhRpuK"
      },
      "outputs": [],
      "source": [
        "# Training and Evaluation\n",
        "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train, epochs=150, batch_size=8, validation_split=0.2, verbose=1)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    unique_labels = np.unique(y_test)\n",
        "    target_names = [label_encoder.classes_[i] for i in unique_labels]\n",
        "\n",
        "    print(classification_report(y_test, y_pred_classes, labels=unique_labels, target_names=target_names))\n",
        "\n",
        "    return y_pred_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tjz4uroRsgr",
        "outputId": "631c876f-fb37-4f14-b4d8-dd99dfc029a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.0138 - loss: 3.0020 - val_accuracy: 0.1250 - val_loss: 3.0114\n",
            "Epoch 2/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1523 - loss: 2.9607 - val_accuracy: 0.1250 - val_loss: 3.0491\n",
            "Epoch 3/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1398 - loss: 2.8924 - val_accuracy: 0.1250 - val_loss: 3.3516\n",
            "Epoch 4/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1523 - loss: 2.8106 - val_accuracy: 0.1250 - val_loss: 3.4647\n",
            "Epoch 5/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1856 - loss: 2.7724 - val_accuracy: 0.1250 - val_loss: 3.4859\n",
            "Epoch 6/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1898 - loss: 2.6760 - val_accuracy: 0.1250 - val_loss: 3.5947\n",
            "Epoch 7/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1523 - loss: 2.7116 - val_accuracy: 0.1250 - val_loss: 3.6896\n",
            "Epoch 8/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1523 - loss: 2.6918 - val_accuracy: 0.1250 - val_loss: 3.7819\n",
            "Epoch 9/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1648 - loss: 2.7206 - val_accuracy: 0.1250 - val_loss: 3.8528\n",
            "Epoch 10/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.0940 - loss: 2.7662 - val_accuracy: 0.1250 - val_loss: 3.9178\n",
            "Epoch 11/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1690 - loss: 2.7482 - val_accuracy: 0.1250 - val_loss: 3.9787\n",
            "Epoch 12/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2273 - loss: 2.5910 - val_accuracy: 0.1250 - val_loss: 4.1156\n",
            "Epoch 13/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1648 - loss: 2.6667 - val_accuracy: 0.1250 - val_loss: 4.0928\n",
            "Epoch 14/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1648 - loss: 2.7385 - val_accuracy: 0.1250 - val_loss: 4.0493\n",
            "Epoch 15/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1606 - loss: 2.6442 - val_accuracy: 0.1250 - val_loss: 4.0531\n",
            "Epoch 16/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1565 - loss: 2.6761 - val_accuracy: 0.1250 - val_loss: 4.0806\n",
            "Epoch 17/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2065 - loss: 2.6526 - val_accuracy: 0.1250 - val_loss: 4.1457\n",
            "Epoch 18/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2106 - loss: 2.5515 - val_accuracy: 0.1250 - val_loss: 4.2217\n",
            "Epoch 19/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2106 - loss: 2.6267 - val_accuracy: 0.1250 - val_loss: 4.2568\n",
            "Epoch 20/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1898 - loss: 2.6143 - val_accuracy: 0.1250 - val_loss: 4.2546\n",
            "Epoch 21/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1065 - loss: 2.7406 - val_accuracy: 0.1250 - val_loss: 4.2383\n",
            "Epoch 22/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1065 - loss: 2.6636 - val_accuracy: 0.1250 - val_loss: 4.2456\n",
            "Epoch 23/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1731 - loss: 2.6188 - val_accuracy: 0.1250 - val_loss: 4.2598\n",
            "Epoch 24/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1981 - loss: 2.6445 - val_accuracy: 0.1250 - val_loss: 4.2667\n",
            "Epoch 25/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1190 - loss: 2.7016 - val_accuracy: 0.1250 - val_loss: 4.2649\n",
            "Epoch 26/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1523 - loss: 2.6258 - val_accuracy: 0.1250 - val_loss: 4.2873\n",
            "Epoch 27/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2023 - loss: 2.6393 - val_accuracy: 0.1250 - val_loss: 4.2955\n",
            "Epoch 28/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1648 - loss: 2.6626 - val_accuracy: 0.1250 - val_loss: 4.3250\n",
            "Epoch 29/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1481 - loss: 2.6257 - val_accuracy: 0.1250 - val_loss: 4.3555\n",
            "Epoch 30/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1731 - loss: 2.5660 - val_accuracy: 0.1250 - val_loss: 4.3889\n",
            "Epoch 31/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1898 - loss: 2.6110 - val_accuracy: 0.1250 - val_loss: 4.4074\n",
            "Epoch 32/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2023 - loss: 2.6195 - val_accuracy: 0.1250 - val_loss: 4.4075\n",
            "Epoch 33/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1398 - loss: 2.6526 - val_accuracy: 0.1250 - val_loss: 4.4116\n",
            "Epoch 34/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1273 - loss: 2.6323 - val_accuracy: 0.1250 - val_loss: 4.4080\n",
            "Epoch 35/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1981 - loss: 2.6616 - val_accuracy: 0.1250 - val_loss: 4.3954\n",
            "Epoch 36/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1523 - loss: 2.6439 - val_accuracy: 0.1250 - val_loss: 4.4115\n",
            "Epoch 37/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2231 - loss: 2.6366 - val_accuracy: 0.1250 - val_loss: 4.4416\n",
            "Epoch 38/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1648 - loss: 2.6580 - val_accuracy: 0.1250 - val_loss: 4.4802\n",
            "Epoch 39/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1523 - loss: 2.6875 - val_accuracy: 0.1250 - val_loss: 4.5018\n",
            "Epoch 40/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2523 - loss: 2.5233 - val_accuracy: 0.1250 - val_loss: 4.5526\n",
            "Epoch 41/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1648 - loss: 2.6903 - val_accuracy: 0.1250 - val_loss: 4.5591\n",
            "Epoch 42/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1565 - loss: 2.7288 - val_accuracy: 0.1250 - val_loss: 4.5488\n",
            "Epoch 43/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1065 - loss: 2.6555 - val_accuracy: 0.1250 - val_loss: 4.5652\n",
            "Epoch 44/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1440 - loss: 2.6047 - val_accuracy: 0.1250 - val_loss: 4.5778\n",
            "Epoch 45/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2106 - loss: 2.5524 - val_accuracy: 0.1250 - val_loss: 4.5425\n",
            "Epoch 46/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1398 - loss: 2.6351 - val_accuracy: 0.1250 - val_loss: 4.4163\n",
            "Epoch 47/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1898 - loss: 2.4491 - val_accuracy: 0.1250 - val_loss: 4.3745\n",
            "Epoch 48/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2578 - loss: 2.3729 - val_accuracy: 0.1250 - val_loss: 4.3745\n",
            "Epoch 49/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1757 - loss: 2.4912 - val_accuracy: 0.0000e+00 - val_loss: 4.3805\n",
            "Epoch 50/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2174 - loss: 2.3628 - val_accuracy: 0.0000e+00 - val_loss: 4.5061\n",
            "Epoch 51/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2023 - loss: 2.4654 - val_accuracy: 0.0000e+00 - val_loss: 4.5501\n",
            "Epoch 52/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1385 - loss: 2.4403 - val_accuracy: 0.1250 - val_loss: 4.3066\n",
            "Epoch 53/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2716 - loss: 2.1958 - val_accuracy: 0.1250 - val_loss: 4.2502\n",
            "Epoch 54/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2703 - loss: 2.2729 - val_accuracy: 0.1250 - val_loss: 4.3152\n",
            "Epoch 55/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2494 - loss: 2.1683 - val_accuracy: 0.1250 - val_loss: 4.4683\n",
            "Epoch 56/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2783 - loss: 2.1773 - val_accuracy: 0.1250 - val_loss: 4.4590\n",
            "Epoch 57/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3184 - loss: 1.9823 - val_accuracy: 0.1250 - val_loss: 4.3920\n",
            "Epoch 58/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4017 - loss: 1.8577 - val_accuracy: 0.1250 - val_loss: 4.5486\n",
            "Epoch 59/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4418 - loss: 1.7380 - val_accuracy: 0.1250 - val_loss: 4.8266\n",
            "Epoch 60/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4572 - loss: 1.6122 - val_accuracy: 0.1250 - val_loss: 4.9017\n",
            "Epoch 61/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3739 - loss: 1.5743 - val_accuracy: 0.1250 - val_loss: 4.6940\n",
            "Epoch 62/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4848 - loss: 1.5377 - val_accuracy: 0.1250 - val_loss: 4.8533\n",
            "Epoch 63/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4723 - loss: 1.4203 - val_accuracy: 0.1250 - val_loss: 5.5283\n",
            "Epoch 64/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5319 - loss: 1.3847 - val_accuracy: 0.1250 - val_loss: 4.6417\n",
            "Epoch 65/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6037 - loss: 1.2713 - val_accuracy: 0.1250 - val_loss: 4.7033\n",
            "Epoch 66/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7412 - loss: 1.0493 - val_accuracy: 0.0000e+00 - val_loss: 4.3122\n",
            "Epoch 67/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6108 - loss: 1.2655 - val_accuracy: 0.1250 - val_loss: 5.0119\n",
            "Epoch 68/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5636 - loss: 1.1898 - val_accuracy: 0.1250 - val_loss: 5.1721\n",
            "Epoch 69/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6342 - loss: 1.2940 - val_accuracy: 0.1250 - val_loss: 4.9153\n",
            "Epoch 70/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6717 - loss: 1.0769 - val_accuracy: 0.0000e+00 - val_loss: 5.5310\n",
            "Epoch 71/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6329 - loss: 1.0610 - val_accuracy: 0.0000e+00 - val_loss: 6.1582\n",
            "Epoch 72/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6483 - loss: 0.9693 - val_accuracy: 0.0000e+00 - val_loss: 5.2945\n",
            "Epoch 73/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6329 - loss: 1.0060 - val_accuracy: 0.0000e+00 - val_loss: 5.7964\n",
            "Epoch 74/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8339 - loss: 0.7278 - val_accuracy: 0.1250 - val_loss: 6.1313\n",
            "Epoch 75/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7772 - loss: 0.6442 - val_accuracy: 0.1250 - val_loss: 5.7778\n",
            "Epoch 76/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8490 - loss: 0.6666 - val_accuracy: 0.1250 - val_loss: 5.1047\n",
            "Epoch 77/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7230 - loss: 0.7930 - val_accuracy: 0.1250 - val_loss: 5.5771\n",
            "Epoch 78/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7797 - loss: 0.7139 - val_accuracy: 0.1250 - val_loss: 6.1210\n",
            "Epoch 79/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7894 - loss: 0.6740 - val_accuracy: 0.1250 - val_loss: 6.1813\n",
            "Epoch 80/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8422 - loss: 0.5713 - val_accuracy: 0.1250 - val_loss: 5.3065\n",
            "Epoch 81/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7659 - loss: 0.7076 - val_accuracy: 0.1250 - val_loss: 5.4679\n",
            "Epoch 82/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8670 - loss: 0.5426 - val_accuracy: 0.1250 - val_loss: 6.2807\n",
            "Epoch 83/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8448 - loss: 0.5025 - val_accuracy: 0.1250 - val_loss: 6.3591\n",
            "Epoch 84/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9779 - loss: 0.4323 - val_accuracy: 0.0000e+00 - val_loss: 6.2765\n",
            "Epoch 85/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9654 - loss: 0.4975 - val_accuracy: 0.1250 - val_loss: 5.9644\n",
            "Epoch 86/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8907 - loss: 0.3788 - val_accuracy: 0.1250 - val_loss: 6.3763\n",
            "Epoch 87/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8836 - loss: 0.3269 - val_accuracy: 0.1250 - val_loss: 6.5462\n",
            "Epoch 88/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9641 - loss: 0.3243 - val_accuracy: 0.1250 - val_loss: 6.3190\n",
            "Epoch 89/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9503 - loss: 0.3112 - val_accuracy: 0.1250 - val_loss: 5.8890\n",
            "Epoch 90/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9045 - loss: 0.3733 - val_accuracy: 0.1250 - val_loss: 6.2315\n",
            "Epoch 91/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8685 - loss: 0.3933 - val_accuracy: 0.1250 - val_loss: 6.7524\n",
            "Epoch 92/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8477 - loss: 0.4478 - val_accuracy: 0.1250 - val_loss: 6.5214\n",
            "Epoch 93/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8034 - loss: 0.4364 - val_accuracy: 0.1250 - val_loss: 6.0109\n",
            "Epoch 94/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8961 - loss: 0.3594 - val_accuracy: 0.1250 - val_loss: 6.7016\n",
            "Epoch 95/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9211 - loss: 0.3039 - val_accuracy: 0.1250 - val_loss: 6.3878\n",
            "Epoch 96/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8865 - loss: 0.4083 - val_accuracy: 0.1250 - val_loss: 6.2413\n",
            "Epoch 97/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9307 - loss: 0.3497 - val_accuracy: 0.1250 - val_loss: 5.9527\n",
            "Epoch 98/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9404 - loss: 0.3395 - val_accuracy: 0.1250 - val_loss: 5.6382\n",
            "Epoch 99/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9045 - loss: 0.3378 - val_accuracy: 0.1250 - val_loss: 5.9784\n",
            "Epoch 100/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9724 - loss: 0.2258 - val_accuracy: 0.1250 - val_loss: 6.3054\n",
            "Epoch 101/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.2036 - val_accuracy: 0.1250 - val_loss: 6.8200\n",
            "Epoch 102/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9336 - loss: 0.3073 - val_accuracy: 0.1250 - val_loss: 6.6113\n",
            "Epoch 103/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8740 - loss: 0.2815 - val_accuracy: 0.1250 - val_loss: 5.8215\n",
            "Epoch 104/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9862 - loss: 0.2816 - val_accuracy: 0.1250 - val_loss: 5.9037\n",
            "Epoch 105/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8711 - loss: 0.3128 - val_accuracy: 0.2500 - val_loss: 5.7524\n",
            "Epoch 106/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9057 - loss: 0.2589 - val_accuracy: 0.2500 - val_loss: 6.3212\n",
            "Epoch 107/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9032 - loss: 0.2746 - val_accuracy: 0.1250 - val_loss: 5.8867\n",
            "Epoch 108/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9862 - loss: 0.2623 - val_accuracy: 0.2500 - val_loss: 5.6459\n",
            "Epoch 109/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8461 - loss: 0.3992 - val_accuracy: 0.1250 - val_loss: 6.4361\n",
            "Epoch 110/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7727 - loss: 0.4238 - val_accuracy: 0.2500 - val_loss: 5.9210\n",
            "Epoch 111/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8323 - loss: 0.3620 - val_accuracy: 0.1250 - val_loss: 6.3459\n",
            "Epoch 112/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8477 - loss: 0.2570 - val_accuracy: 0.1250 - val_loss: 6.3068\n",
            "Epoch 113/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8586 - loss: 0.2857 - val_accuracy: 0.2500 - val_loss: 5.6505\n",
            "Epoch 114/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8920 - loss: 0.3499 - val_accuracy: 0.2500 - val_loss: 5.7775\n",
            "Epoch 115/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9516 - loss: 0.2121 - val_accuracy: 0.1250 - val_loss: 5.7971\n",
            "Epoch 116/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1750 - val_accuracy: 0.2500 - val_loss: 5.7214\n",
            "Epoch 117/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9404 - loss: 0.1869 - val_accuracy: 0.2500 - val_loss: 5.7300\n",
            "Epoch 118/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9654 - loss: 0.1401 - val_accuracy: 0.2500 - val_loss: 6.0912\n",
            "Epoch 119/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.1412 - val_accuracy: 0.1250 - val_loss: 6.2731\n",
            "Epoch 120/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0989 - val_accuracy: 0.2500 - val_loss: 6.2509\n",
            "Epoch 121/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1179 - val_accuracy: 0.2500 - val_loss: 6.2140\n",
            "Epoch 122/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.1171 - val_accuracy: 0.1250 - val_loss: 6.2078\n",
            "Epoch 123/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0958 - val_accuracy: 0.1250 - val_loss: 6.2304\n",
            "Epoch 124/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0870 - val_accuracy: 0.1250 - val_loss: 6.2067\n",
            "Epoch 125/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0890 - val_accuracy: 0.2500 - val_loss: 6.1992\n",
            "Epoch 126/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0792 - val_accuracy: 0.2500 - val_loss: 6.2036\n",
            "Epoch 127/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0675 - val_accuracy: 0.2500 - val_loss: 6.1979\n",
            "Epoch 128/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0716 - val_accuracy: 0.2500 - val_loss: 6.2108\n",
            "Epoch 129/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0529 - val_accuracy: 0.2500 - val_loss: 6.2195\n",
            "Epoch 130/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0665 - val_accuracy: 0.2500 - val_loss: 6.2418\n",
            "Epoch 131/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0535 - val_accuracy: 0.2500 - val_loss: 6.2632\n",
            "Epoch 132/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0539 - val_accuracy: 0.2500 - val_loss: 6.2996\n",
            "Epoch 133/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0494 - val_accuracy: 0.2500 - val_loss: 6.3359\n",
            "Epoch 134/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 0.2500 - val_loss: 6.3783\n",
            "Epoch 135/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0476 - val_accuracy: 0.2500 - val_loss: 6.3815\n",
            "Epoch 136/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0497 - val_accuracy: 0.2500 - val_loss: 6.3164\n",
            "Epoch 137/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0498 - val_accuracy: 0.2500 - val_loss: 6.2947\n",
            "Epoch 138/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0420 - val_accuracy: 0.2500 - val_loss: 6.3041\n",
            "Epoch 139/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0366 - val_accuracy: 0.2500 - val_loss: 6.3323\n",
            "Epoch 140/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0393 - val_accuracy: 0.2500 - val_loss: 6.3649\n",
            "Epoch 141/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0374 - val_accuracy: 0.2500 - val_loss: 6.3950\n",
            "Epoch 142/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0384 - val_accuracy: 0.2500 - val_loss: 6.4123\n",
            "Epoch 143/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0378 - val_accuracy: 0.2500 - val_loss: 6.4270\n",
            "Epoch 144/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0388 - val_accuracy: 0.2500 - val_loss: 6.4242\n",
            "Epoch 145/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0380 - val_accuracy: 0.2500 - val_loss: 6.4253\n",
            "Epoch 146/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0307 - val_accuracy: 0.2500 - val_loss: 6.4331\n",
            "Epoch 147/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0341 - val_accuracy: 0.2500 - val_loss: 6.4399\n",
            "Epoch 148/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0319 - val_accuracy: 0.2500 - val_loss: 6.4501\n",
            "Epoch 149/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0349 - val_accuracy: 0.2500 - val_loss: 6.4607\n",
            "Epoch 150/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0283 - val_accuracy: 0.2500 - val_loss: 6.4725\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "Business and Productivity       0.00      0.00      0.00       1.0\n",
            "       Data and Analytics       0.00      0.00      0.00       1.0\n",
            "                   Design       0.00      0.00      0.00       1.0\n",
            "   Education and Training       0.00      0.00      0.00       2.0\n",
            "Marketing and Advertising       0.00      0.00      0.00       1.0\n",
            "          Music and Audio       0.00      0.00      0.00       1.0\n",
            "    Retail and E-commerce       0.00      0.00      0.00       1.0\n",
            "     Science and Research       0.00      0.00      0.00       1.0\n",
            "               Visual Art       0.00      0.00      0.00       1.0\n",
            "\n",
            "                micro avg       0.00      0.00      0.00      10.0\n",
            "                macro avg       0.00      0.00      0.00      10.0\n",
            "             weighted avg       0.00      0.00      0.00      10.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate models\n",
        "print(\"Training LSTM model...\")\n",
        "y_pred_lstm = train_and_evaluate(model_lstm, X_train_bow, X_test_bow, y_train, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RM7cO9GRuZT",
        "outputId": "65e62fd8-97ed-4cc6-d17d-2e85f8a1b746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GRU model...\n",
            "Epoch 1/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 390ms/step - accuracy: 0.0497 - loss: 2.9977 - val_accuracy: 0.1250 - val_loss: 2.9968\n",
            "Epoch 2/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1731 - loss: 2.9445 - val_accuracy: 0.1250 - val_loss: 3.0045\n",
            "Epoch 3/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.1273 - loss: 2.9038 - val_accuracy: 0.1250 - val_loss: 3.0554\n",
            "Epoch 4/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1523 - loss: 2.8126 - val_accuracy: 0.1250 - val_loss: 3.2169\n",
            "Epoch 5/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.1773 - loss: 2.7432 - val_accuracy: 0.1250 - val_loss: 3.4514\n",
            "Epoch 6/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2106 - loss: 2.6449 - val_accuracy: 0.1250 - val_loss: 3.4914\n",
            "Epoch 7/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1648 - loss: 2.6427 - val_accuracy: 0.1250 - val_loss: 3.4816\n",
            "Epoch 8/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.2481 - loss: 2.6070 - val_accuracy: 0.1250 - val_loss: 3.5719\n",
            "Epoch 9/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1856 - loss: 2.6761 - val_accuracy: 0.1250 - val_loss: 3.7078\n",
            "Epoch 10/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1440 - loss: 2.7135 - val_accuracy: 0.1250 - val_loss: 3.8063\n",
            "Epoch 11/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1981 - loss: 2.6589 - val_accuracy: 0.1250 - val_loss: 3.9613\n",
            "Epoch 12/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1148 - loss: 2.7469 - val_accuracy: 0.1250 - val_loss: 3.9816\n",
            "Epoch 13/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2023 - loss: 2.6451 - val_accuracy: 0.1250 - val_loss: 4.0624\n",
            "Epoch 14/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1606 - loss: 2.7007 - val_accuracy: 0.1250 - val_loss: 4.0550\n",
            "Epoch 15/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2273 - loss: 2.5392 - val_accuracy: 0.1250 - val_loss: 4.0924\n",
            "Epoch 16/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1273 - loss: 2.6786 - val_accuracy: 0.1250 - val_loss: 4.0637\n",
            "Epoch 17/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1898 - loss: 2.6252 - val_accuracy: 0.1250 - val_loss: 4.1144\n",
            "Epoch 18/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1565 - loss: 2.5979 - val_accuracy: 0.1250 - val_loss: 4.1738\n",
            "Epoch 19/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1523 - loss: 2.6686 - val_accuracy: 0.1250 - val_loss: 4.2205\n",
            "Epoch 20/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1898 - loss: 2.5474 - val_accuracy: 0.1250 - val_loss: 4.3438\n",
            "Epoch 21/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.1786 - loss: 2.6372 - val_accuracy: 0.1250 - val_loss: 4.3405\n",
            "Epoch 22/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2244 - loss: 2.4830 - val_accuracy: 0.1250 - val_loss: 4.4823\n",
            "Epoch 23/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2328 - loss: 2.5028 - val_accuracy: 0.1250 - val_loss: 4.5590\n",
            "Epoch 24/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1856 - loss: 2.4612 - val_accuracy: 0.0000e+00 - val_loss: 4.6150\n",
            "Epoch 25/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.1302 - loss: 2.6635 - val_accuracy: 0.0000e+00 - val_loss: 4.5606\n",
            "Epoch 26/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.1911 - loss: 2.4863 - val_accuracy: 0.0000e+00 - val_loss: 4.7883\n",
            "Epoch 27/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2244 - loss: 2.4071 - val_accuracy: 0.0000e+00 - val_loss: 5.0323\n",
            "Epoch 28/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.1869 - loss: 2.3471 - val_accuracy: 0.0000e+00 - val_loss: 5.2257\n",
            "Epoch 29/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1869 - loss: 2.4288 - val_accuracy: 0.0000e+00 - val_loss: 5.2327\n",
            "Epoch 30/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2216 - loss: 2.4177 - val_accuracy: 0.0000e+00 - val_loss: 5.2213\n",
            "Epoch 31/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3325 - loss: 2.2433 - val_accuracy: 0.1250 - val_loss: 5.2023\n",
            "Epoch 32/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4629 - loss: 2.1138 - val_accuracy: 0.1250 - val_loss: 5.2915\n",
            "Epoch 33/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3171 - loss: 2.3029 - val_accuracy: 0.1250 - val_loss: 5.3944\n",
            "Epoch 34/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3338 - loss: 2.3330 - val_accuracy: 0.1250 - val_loss: 5.5610\n",
            "Epoch 35/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3283 - loss: 2.0852 - val_accuracy: 0.1250 - val_loss: 5.6986\n",
            "Epoch 36/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3976 - loss: 2.0657 - val_accuracy: 0.1250 - val_loss: 5.7793\n",
            "Epoch 37/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3684 - loss: 2.0871 - val_accuracy: 0.1250 - val_loss: 5.7603\n",
            "Epoch 38/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4033 - loss: 1.8260 - val_accuracy: 0.1250 - val_loss: 5.4508\n",
            "Epoch 39/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2895 - loss: 2.0247 - val_accuracy: 0.0000e+00 - val_loss: 5.4830\n",
            "Epoch 40/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3379 - loss: 2.0661 - val_accuracy: 0.0000e+00 - val_loss: 5.3710\n",
            "Epoch 41/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4822 - loss: 1.9440 - val_accuracy: 0.1250 - val_loss: 5.7436\n",
            "Epoch 42/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4476 - loss: 1.7326 - val_accuracy: 0.1250 - val_loss: 5.8669\n",
            "Epoch 43/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2241 - loss: 2.0167 - val_accuracy: 0.1250 - val_loss: 5.8912\n",
            "Epoch 44/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3588 - loss: 1.8277 - val_accuracy: 0.1250 - val_loss: 5.8324\n",
            "Epoch 45/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3184 - loss: 1.8113 - val_accuracy: 0.0000e+00 - val_loss: 5.8509\n",
            "Epoch 46/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4017 - loss: 1.7828 - val_accuracy: 0.0000e+00 - val_loss: 6.0025\n",
            "Epoch 47/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4376 - loss: 1.6693 - val_accuracy: 0.0000e+00 - val_loss: 6.1184\n",
            "Epoch 48/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5293 - loss: 1.6431 - val_accuracy: 0.0000e+00 - val_loss: 6.0783\n",
            "Epoch 49/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4764 - loss: 1.7456 - val_accuracy: 0.0000e+00 - val_loss: 5.9958\n",
            "Epoch 50/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4889 - loss: 1.7696 - val_accuracy: 0.0000e+00 - val_loss: 6.1111\n",
            "Epoch 51/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5639 - loss: 1.3908 - val_accuracy: 0.0000e+00 - val_loss: 6.2355\n",
            "Epoch 52/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4486 - loss: 1.8905 - val_accuracy: 0.0000e+00 - val_loss: 6.2506\n",
            "Epoch 53/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4751 - loss: 1.4912 - val_accuracy: 0.0000e+00 - val_loss: 5.9392\n",
            "Epoch 54/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4376 - loss: 1.4737 - val_accuracy: 0.0000e+00 - val_loss: 5.7873\n",
            "Epoch 55/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5335 - loss: 1.4049 - val_accuracy: 0.0000e+00 - val_loss: 6.3188\n",
            "Epoch 56/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4902 - loss: 1.5301 - val_accuracy: 0.0000e+00 - val_loss: 6.7220\n",
            "Epoch 57/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5819 - loss: 1.3660 - val_accuracy: 0.0000e+00 - val_loss: 6.4785\n",
            "Epoch 58/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4944 - loss: 1.3117 - val_accuracy: 0.0000e+00 - val_loss: 6.1445\n",
            "Epoch 59/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5527 - loss: 1.2887 - val_accuracy: 0.0000e+00 - val_loss: 6.2472\n",
            "Epoch 60/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6136 - loss: 1.1817 - val_accuracy: 0.0000e+00 - val_loss: 5.9837\n",
            "Epoch 61/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5319 - loss: 1.2752 - val_accuracy: 0.0000e+00 - val_loss: 6.5084\n",
            "Epoch 62/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6303 - loss: 1.0769 - val_accuracy: 0.0000e+00 - val_loss: 6.5141\n",
            "Epoch 63/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6967 - loss: 1.0224 - val_accuracy: 0.0000e+00 - val_loss: 6.8024\n",
            "Epoch 64/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7800 - loss: 0.8051 - val_accuracy: 0.0000e+00 - val_loss: 6.8932\n",
            "Epoch 65/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7813 - loss: 0.7681 - val_accuracy: 0.0000e+00 - val_loss: 6.8250\n",
            "Epoch 66/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7563 - loss: 0.8259 - val_accuracy: 0.0000e+00 - val_loss: 6.9782\n",
            "Epoch 67/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6134 - loss: 1.0510 - val_accuracy: 0.0000e+00 - val_loss: 6.8473\n",
            "Epoch 68/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8118 - loss: 0.6836 - val_accuracy: 0.0000e+00 - val_loss: 6.8873\n",
            "Epoch 69/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5649 - loss: 1.0652 - val_accuracy: 0.0000e+00 - val_loss: 6.9856\n",
            "Epoch 70/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7547 - loss: 0.9311 - val_accuracy: 0.0000e+00 - val_loss: 7.1512\n",
            "Epoch 71/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8339 - loss: 0.7178 - val_accuracy: 0.0000e+00 - val_loss: 7.0050\n",
            "Epoch 72/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7522 - loss: 0.6831 - val_accuracy: 0.0000e+00 - val_loss: 7.1441\n",
            "Epoch 73/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8269 - loss: 0.7072 - val_accuracy: 0.0000e+00 - val_loss: 7.0760\n",
            "Epoch 74/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7576 - loss: 0.8432 - val_accuracy: 0.0000e+00 - val_loss: 7.2479\n",
            "Epoch 75/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7769 - loss: 0.7204 - val_accuracy: 0.0000e+00 - val_loss: 7.1744\n",
            "Epoch 76/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7287 - loss: 0.6968 - val_accuracy: 0.0000e+00 - val_loss: 7.2312\n",
            "Epoch 77/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7964 - loss: 0.6873 - val_accuracy: 0.0000e+00 - val_loss: 7.3062\n",
            "Epoch 78/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7397 - loss: 0.7730 - val_accuracy: 0.0000e+00 - val_loss: 7.4407\n",
            "Epoch 79/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8573 - loss: 0.6452 - val_accuracy: 0.0000e+00 - val_loss: 7.5868\n",
            "Epoch 80/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8586 - loss: 0.5370 - val_accuracy: 0.0000e+00 - val_loss: 7.6279\n",
            "Epoch 81/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7076 - loss: 0.6355 - val_accuracy: 0.1250 - val_loss: 7.0690\n",
            "Epoch 82/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6730 - loss: 0.7050 - val_accuracy: 0.0000e+00 - val_loss: 7.1057\n",
            "Epoch 83/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6922 - loss: 0.8754 - val_accuracy: 0.0000e+00 - val_loss: 7.2774\n",
            "Epoch 84/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5912 - loss: 0.8504 - val_accuracy: 0.0000e+00 - val_loss: 7.3787\n",
            "Epoch 85/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7797 - loss: 0.6494 - val_accuracy: 0.0000e+00 - val_loss: 7.7082\n",
            "Epoch 86/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7797 - loss: 0.6290 - val_accuracy: 0.0000e+00 - val_loss: 7.5461\n",
            "Epoch 87/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8461 - loss: 0.5327 - val_accuracy: 0.0000e+00 - val_loss: 7.6872\n",
            "Epoch 88/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7769 - loss: 0.4913 - val_accuracy: 0.0000e+00 - val_loss: 7.4442\n",
            "Epoch 89/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8810 - loss: 0.4418 - val_accuracy: 0.0000e+00 - val_loss: 7.6203\n",
            "Epoch 90/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8615 - loss: 0.3577 - val_accuracy: 0.0000e+00 - val_loss: 7.7960\n",
            "Epoch 91/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9057 - loss: 0.4761 - val_accuracy: 0.0000e+00 - val_loss: 7.6102\n",
            "Epoch 92/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9420 - loss: 0.2606 - val_accuracy: 0.0000e+00 - val_loss: 7.5026\n",
            "Epoch 93/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8836 - loss: 0.3234 - val_accuracy: 0.0000e+00 - val_loss: 7.6428\n",
            "Epoch 94/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9724 - loss: 0.2309 - val_accuracy: 0.0000e+00 - val_loss: 7.7353\n",
            "Epoch 95/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9557 - loss: 0.2783 - val_accuracy: 0.0000e+00 - val_loss: 7.6721\n",
            "Epoch 96/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9654 - loss: 0.2732 - val_accuracy: 0.0000e+00 - val_loss: 7.4979\n",
            "Epoch 97/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9654 - loss: 0.2250 - val_accuracy: 0.0000e+00 - val_loss: 7.5054\n",
            "Epoch 98/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9057 - loss: 0.2411 - val_accuracy: 0.0000e+00 - val_loss: 7.4962\n",
            "Epoch 99/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9862 - loss: 0.2198 - val_accuracy: 0.0000e+00 - val_loss: 7.5988\n",
            "Epoch 100/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2654 - val_accuracy: 0.0000e+00 - val_loss: 7.6181\n",
            "Epoch 101/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9266 - loss: 0.2835 - val_accuracy: 0.0000e+00 - val_loss: 7.7160\n",
            "Epoch 102/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9862 - loss: 0.2005 - val_accuracy: 0.0000e+00 - val_loss: 7.7674\n",
            "Epoch 103/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1726 - val_accuracy: 0.0000e+00 - val_loss: 7.8003\n",
            "Epoch 104/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1760 - val_accuracy: 0.0000e+00 - val_loss: 7.6605\n",
            "Epoch 105/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9266 - loss: 0.2672 - val_accuracy: 0.0000e+00 - val_loss: 7.6170\n",
            "Epoch 106/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8394 - loss: 0.3940 - val_accuracy: 0.0000e+00 - val_loss: 7.9133\n",
            "Epoch 107/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8422 - loss: 0.3339 - val_accuracy: 0.0000e+00 - val_loss: 7.8323\n",
            "Epoch 108/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9432 - loss: 0.3251 - val_accuracy: 0.0000e+00 - val_loss: 7.8727\n",
            "Epoch 109/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9779 - loss: 0.2179 - val_accuracy: 0.0000e+00 - val_loss: 7.5747\n",
            "Epoch 110/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9779 - loss: 0.2130 - val_accuracy: 0.0000e+00 - val_loss: 7.6259\n",
            "Epoch 111/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9404 - loss: 0.2310 - val_accuracy: 0.1250 - val_loss: 7.4609\n",
            "Epoch 112/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9404 - loss: 0.2143 - val_accuracy: 0.0000e+00 - val_loss: 7.4333\n",
            "Epoch 113/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.1661 - val_accuracy: 0.0000e+00 - val_loss: 7.5993\n",
            "Epoch 114/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1018 - val_accuracy: 0.0000e+00 - val_loss: 7.6184\n",
            "Epoch 115/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0999 - val_accuracy: 0.0000e+00 - val_loss: 7.7308\n",
            "Epoch 116/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9779 - loss: 0.0923 - val_accuracy: 0.0000e+00 - val_loss: 7.7312\n",
            "Epoch 117/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9654 - loss: 0.1013 - val_accuracy: 0.0000e+00 - val_loss: 7.6378\n",
            "Epoch 118/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9654 - loss: 0.1015 - val_accuracy: 0.0000e+00 - val_loss: 7.6550\n",
            "Epoch 119/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0928 - val_accuracy: 0.0000e+00 - val_loss: 7.6065\n",
            "Epoch 120/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1010 - val_accuracy: 0.0000e+00 - val_loss: 7.6442\n",
            "Epoch 121/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0699 - val_accuracy: 0.0000e+00 - val_loss: 7.8220\n",
            "Epoch 122/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0735 - val_accuracy: 0.0000e+00 - val_loss: 7.8369\n",
            "Epoch 123/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1061 - val_accuracy: 0.0000e+00 - val_loss: 7.7370\n",
            "Epoch 124/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0931 - val_accuracy: 0.0000e+00 - val_loss: 7.8918\n",
            "Epoch 125/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0697 - val_accuracy: 0.0000e+00 - val_loss: 7.7526\n",
            "Epoch 126/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0861 - val_accuracy: 0.0000e+00 - val_loss: 7.7113\n",
            "Epoch 127/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0830 - val_accuracy: 0.0000e+00 - val_loss: 7.9149\n",
            "Epoch 128/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0664 - val_accuracy: 0.0000e+00 - val_loss: 7.8713\n",
            "Epoch 129/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0657 - val_accuracy: 0.0000e+00 - val_loss: 7.9710\n",
            "Epoch 130/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0602 - val_accuracy: 0.0000e+00 - val_loss: 7.9053\n",
            "Epoch 131/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0663 - val_accuracy: 0.0000e+00 - val_loss: 8.0491\n",
            "Epoch 132/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0471 - val_accuracy: 0.0000e+00 - val_loss: 7.8870\n",
            "Epoch 133/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9779 - loss: 0.0694 - val_accuracy: 0.0000e+00 - val_loss: 8.0345\n",
            "Epoch 134/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0766 - val_accuracy: 0.0000e+00 - val_loss: 8.0778\n",
            "Epoch 135/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0638 - val_accuracy: 0.0000e+00 - val_loss: 8.1110\n",
            "Epoch 136/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9641 - loss: 0.1181 - val_accuracy: 0.0000e+00 - val_loss: 7.9432\n",
            "Epoch 137/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8477 - loss: 0.4861 - val_accuracy: 0.1250 - val_loss: 7.6579\n",
            "Epoch 138/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8769 - loss: 0.3334 - val_accuracy: 0.0000e+00 - val_loss: 7.6880\n",
            "Epoch 139/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9057 - loss: 0.4580 - val_accuracy: 0.0000e+00 - val_loss: 7.7755\n",
            "Epoch 140/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7284 - loss: 1.0019 - val_accuracy: 0.0000e+00 - val_loss: 7.4888\n",
            "Epoch 141/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7852 - loss: 0.3160 - val_accuracy: 0.0000e+00 - val_loss: 7.4062\n",
            "Epoch 142/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8685 - loss: 0.3007 - val_accuracy: 0.0000e+00 - val_loss: 7.4050\n",
            "Epoch 143/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7672 - loss: 0.8368 - val_accuracy: 0.0000e+00 - val_loss: 8.3057\n",
            "Epoch 144/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7230 - loss: 0.8013 - val_accuracy: 0.0000e+00 - val_loss: 8.4770\n",
            "Epoch 145/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7993 - loss: 0.6421 - val_accuracy: 0.0000e+00 - val_loss: 8.4737\n",
            "Epoch 146/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6371 - loss: 0.9545 - val_accuracy: 0.0000e+00 - val_loss: 8.2977\n",
            "Epoch 147/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8807 - loss: 0.4760 - val_accuracy: 0.0000e+00 - val_loss: 8.4457\n",
            "Epoch 148/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9182 - loss: 0.2268 - val_accuracy: 0.0000e+00 - val_loss: 8.5397\n",
            "Epoch 149/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9295 - loss: 0.3068 - val_accuracy: 0.0000e+00 - val_loss: 8.5551\n",
            "Epoch 150/150\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8144 - loss: 0.3061 - val_accuracy: 0.0000e+00 - val_loss: 8.7026\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "Business and Productivity       0.00      0.00      0.00         1\n",
            "       Data and Analytics       0.00      0.00      0.00         1\n",
            "                   Design       0.00      0.00      0.00         1\n",
            "   Education and Training       0.00      0.00      0.00         2\n",
            "Marketing and Advertising       0.00      0.00      0.00         1\n",
            "          Music and Audio       0.00      0.00      0.00         1\n",
            "    Retail and E-commerce       0.00      0.00      0.00         1\n",
            "     Science and Research       0.00      0.00      0.00         1\n",
            "               Visual Art       0.50      1.00      0.67         1\n",
            "\n",
            "                micro avg       0.25      0.10      0.14        10\n",
            "                macro avg       0.06      0.11      0.07        10\n",
            "             weighted avg       0.05      0.10      0.07        10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Training GRU model...\")\n",
        "y_pred_gru = train_and_evaluate(model_gru, X_train_bow, X_test_bow, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt5pviA_RxAz",
        "outputId": "5fca4d42-cbd4-4e65-fa18-ba5ae1fd0086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Define BERT Model\n",
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "KkjF9B01R4OW"
      },
      "outputs": [],
      "source": [
        "# Tokenize and Encode for BERT\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "WulYfbppR68-"
      },
      "outputs": [],
      "source": [
        "max_len = 50\n",
        "train_dataset = CustomDataset(df['prompt'].tolist(), df['label'].tolist(), bert_tokenizer, max_len)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-NPcVVhR82m"
      },
      "outputs": [],
      "source": [
        "# Training function for BERT\n",
        "def train_bert_model(model, train_loader, epochs):\n",
        "    model.train()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "    for epoch in range(epochs):\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids']\n",
        "            attention_mask = batch['attention_mask']\n",
        "            labels = batch['label']\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbCiDfhRR-2a",
        "outputId": "626fae21-1f57-4006-d92b-06f3eef06860"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BERT model...\n",
            "Epoch 1/60, Loss: 3.118049144744873\n",
            "Epoch 2/60, Loss: 3.131500244140625\n",
            "Epoch 3/60, Loss: 2.7004053592681885\n",
            "Epoch 4/60, Loss: 2.890322208404541\n",
            "Epoch 5/60, Loss: 2.5996086597442627\n",
            "Epoch 6/60, Loss: 2.4284496307373047\n",
            "Epoch 7/60, Loss: 2.6128926277160645\n",
            "Epoch 8/60, Loss: 2.4430794715881348\n",
            "Epoch 9/60, Loss: 2.2674856185913086\n",
            "Epoch 10/60, Loss: 2.124821186065674\n",
            "Epoch 11/60, Loss: 1.8658958673477173\n",
            "Epoch 12/60, Loss: 1.9452930688858032\n",
            "Epoch 13/60, Loss: 1.7551578283309937\n",
            "Epoch 14/60, Loss: 1.504683256149292\n",
            "Epoch 15/60, Loss: 1.3911263942718506\n",
            "Epoch 16/60, Loss: 1.5383832454681396\n",
            "Epoch 17/60, Loss: 1.553912878036499\n",
            "Epoch 18/60, Loss: 1.4498580694198608\n",
            "Epoch 19/60, Loss: 1.3868862390518188\n",
            "Epoch 20/60, Loss: 1.1675071716308594\n",
            "Epoch 21/60, Loss: 1.0797951221466064\n",
            "Epoch 22/60, Loss: 1.1791919469833374\n",
            "Epoch 23/60, Loss: 1.3023689985275269\n",
            "Epoch 24/60, Loss: 1.1169284582138062\n",
            "Epoch 25/60, Loss: 0.9098499417304993\n",
            "Epoch 26/60, Loss: 0.977121889591217\n",
            "Epoch 27/60, Loss: 0.8603891730308533\n",
            "Epoch 28/60, Loss: 0.7155212163925171\n",
            "Epoch 29/60, Loss: 0.5841838717460632\n",
            "Epoch 30/60, Loss: 0.5037849545478821\n",
            "Epoch 31/60, Loss: 0.6041117906570435\n",
            "Epoch 32/60, Loss: 0.5851060152053833\n",
            "Epoch 33/60, Loss: 0.6329609751701355\n",
            "Epoch 34/60, Loss: 0.4850524067878723\n",
            "Epoch 35/60, Loss: 0.3895064890384674\n",
            "Epoch 36/60, Loss: 0.4599693715572357\n",
            "Epoch 37/60, Loss: 0.4936191141605377\n",
            "Epoch 38/60, Loss: 0.42384132742881775\n",
            "Epoch 39/60, Loss: 0.3425140082836151\n",
            "Epoch 40/60, Loss: 0.3960602879524231\n",
            "Epoch 41/60, Loss: 0.3380396068096161\n",
            "Epoch 42/60, Loss: 0.3280694782733917\n",
            "Epoch 43/60, Loss: 0.34120669960975647\n",
            "Epoch 44/60, Loss: 0.314106285572052\n",
            "Epoch 45/60, Loss: 0.23831041157245636\n",
            "Epoch 46/60, Loss: 0.2212858945131302\n",
            "Epoch 47/60, Loss: 0.212164044380188\n",
            "Epoch 48/60, Loss: 0.22985278069972992\n",
            "Epoch 49/60, Loss: 0.2787810266017914\n",
            "Epoch 50/60, Loss: 0.20032967627048492\n",
            "Epoch 51/60, Loss: 0.2617740035057068\n",
            "Epoch 52/60, Loss: 0.21027711033821106\n",
            "Epoch 53/60, Loss: 0.2575569450855255\n",
            "Epoch 54/60, Loss: 0.2216271311044693\n",
            "Epoch 55/60, Loss: 0.24241916835308075\n",
            "Epoch 56/60, Loss: 0.18418076634407043\n",
            "Epoch 57/60, Loss: 0.18178094923496246\n",
            "Epoch 58/60, Loss: 0.21982255578041077\n",
            "Epoch 59/60, Loss: 0.13363413512706757\n",
            "Epoch 60/60, Loss: 0.10656237602233887\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train BERT Model\n",
        "print(\"Training BERT model...\")\n",
        "train_bert_model(bert_model, train_loader, epochs=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "GjfZPtz-SAk9"
      },
      "outputs": [],
      "source": [
        "def evaluate_bert_model(model, texts, labels):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        encoding = bert_tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding['input_ids']\n",
        "        attention_mask = encoding['attention_mask']\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids, attention_mask=attention_mask)\n",
        "        pred_class = torch.argmax(output.logits, dim=1).item()\n",
        "        predictions.append(pred_class)\n",
        "        true_labels.append(label)\n",
        "\n",
        "    unique_labels = np.unique(true_labels)\n",
        "    target_names = [label_encoder.classes_[i] for i in unique_labels]\n",
        "    print(classification_report(true_labels, predictions, labels=unique_labels, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wTZzyM-Skxu",
        "outputId": "3c09b32d-e50d-471d-c319-3c6ef6ed9e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating BERT model...\n",
            "                                 precision    recall  f1-score   support\n",
            "\n",
            "      Business and Productivity       1.00      1.00      1.00         2\n",
            "                  Communication       1.00      1.00      1.00         6\n",
            "             Data and Analytics       1.00      1.00      1.00         2\n",
            "                         Design       1.00      1.00      1.00         2\n",
            "         Education and Training       1.00      1.00      1.00         2\n",
            "            Health and Wellness       1.00      1.00      1.00         2\n",
            "                       Homework       1.00      1.00      1.00         2\n",
            "                Human Resources       1.00      1.00      1.00         2\n",
            "Legal and Professional Services       1.00      1.00      1.00         2\n",
            "      Marketing and Advertising       1.00      1.00      1.00         4\n",
            "           Media and Journalism       1.00      1.00      1.00         1\n",
            "                Music and Audio       1.00      1.00      1.00         3\n",
            "                         Others       1.00      1.00      1.00         1\n",
            "    Programming and Development       1.00      1.00      1.00         2\n",
            "          Retail and E-commerce       1.00      1.00      1.00         2\n",
            "           Science and Research       1.00      1.00      1.00         2\n",
            "   Translation and Localization       1.00      1.00      1.00         1\n",
            "         Travel and Hospitality       1.00      1.00      1.00         2\n",
            "                     Visual Art       1.00      1.00      1.00         4\n",
            "   Writing and Content Creation       1.00      1.00      1.00         3\n",
            "\n",
            "                       accuracy                           1.00        47\n",
            "                      macro avg       1.00      1.00      1.00        47\n",
            "                   weighted avg       1.00      1.00      1.00        47\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating BERT model...\")\n",
        "evaluate_bert_model(bert_model, df['prompt'].tolist(), df['label'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "XU-4UJomSnJR"
      },
      "outputs": [],
      "source": [
        "# Prediction Function for User Input\n",
        "def predict_category(text, model, tokenizer, vectorizer=None, max_len=None):\n",
        "    if vectorizer:\n",
        "        text = [text]  # Wrap text in a list\n",
        "        if isinstance(vectorizer, CountVectorizer):\n",
        "            text_vec = vectorizer.transform(text).toarray()\n",
        "        elif isinstance(vectorizer, TfidfVectorizer):\n",
        "            text_vec = vectorizer.transform(text).toarray()\n",
        "        elif isinstance(vectorizer, Word2Vec):\n",
        "            text_vec = np.array([get_word2vec_features(text[0])])\n",
        "        prediction = model.predict(text_vec)\n",
        "    elif tokenizer and max_len:\n",
        "        encoding = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding['input_ids']\n",
        "        attention_mask = encoding['attention_mask']\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids, attention_mask=attention_mask)\n",
        "        prediction = torch.argmax(output.logits, dim=1).item()\n",
        "    return label_encoder.classes_[prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "9fZw4yUoSqLN"
      },
      "outputs": [],
      "source": [
        "def predict_category(text, model, tokenizer=None, vectorizer=None, max_len=None):\n",
        "    if vectorizer:\n",
        "        text = [text]  # Wrap text in a list\n",
        "        if isinstance(vectorizer, CountVectorizer):\n",
        "            text_vec = vectorizer.transform(text).toarray()\n",
        "        elif isinstance(vectorizer, TfidfVectorizer):\n",
        "            text_vec = vectorizer.transform(text).toarray()\n",
        "        elif isinstance(vectorizer, Word2Vec):\n",
        "            text_vec = np.array([get_word2vec_features(text[0])])\n",
        "        prediction = model.predict(text_vec)\n",
        "        prediction = np.argmax(prediction, axis=1)[0]  # Get the index of the highest probability\n",
        "    elif tokenizer and max_len:\n",
        "        encoding = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding['input_ids']\n",
        "        attention_mask = encoding['attention_mask']\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids, attention_mask=attention_mask)\n",
        "        prediction = torch.argmax(output.logits, dim=1).item()\n",
        "\n",
        "    if isinstance(prediction, np.ndarray):  # Convert numpy array to integer if necessary\n",
        "        prediction = prediction[0]\n",
        "\n",
        "    try:\n",
        "        return label_encoder.classes_[prediction]\n",
        "    except IndexError as e:\n",
        "        print(f\"Error: {e}, Prediction: {prediction}, Classes: {label_encoder.classes_}\")\n",
        "        return \"Unknown Category\"\n",
        "\n",
        "# Example Usage\n",
        "def user_input():\n",
        "    while True:\n",
        "        user_prompt = input(\"Enter a prompt: \")\n",
        "        if user_prompt.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        print(\"LSTM Model Prediction:\", predict_category(user_prompt, model_lstm, None, bow_vectorizer))\n",
        "        print(\"GRU Model Prediction:\", predict_category(user_prompt, model_gru, None, bow_vectorizer))\n",
        "        print(\"BERT Model Prediction:\", predict_category(user_prompt, bert_model, bert_tokenizer, max_len=max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2txTABPSxLG",
        "outputId": "e7956ade-5c85-4d82-bf3e-130fe45872e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a prompt: Develop educational content for an online course\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n",
            "LSTM Model Prediction: Legal and Professional Services\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
            "GRU Model Prediction: Legal and Professional Services\n",
            "BERT Model Prediction: Education and Training\n",
            "Enter a prompt: Organize an event plan for a wedding\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "LSTM Model Prediction: Legal and Professional Services\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "GRU Model Prediction: Programming and Development\n",
            "BERT Model Prediction: Travel and Hospitality\n",
            "Enter a prompt: Create a healthy meal plan for a week\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "LSTM Model Prediction: Health and Wellness\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "GRU Model Prediction: Health and Wellness\n",
            "BERT Model Prediction: Health and Wellness\n",
            "Enter a prompt: Draft a resume for a job application\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "LSTM Model Prediction: Legal and Professional Services\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "GRU Model Prediction: Programming and Development\n",
            "BERT Model Prediction: Human Resources\n",
            "Enter a prompt: Write detailed product descriptions for an online shop\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "LSTM Model Prediction: Marketing and Advertising\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "GRU Model Prediction: Marketing and Advertising\n",
            "BERT Model Prediction: Retail and E-commerce\n",
            "Enter a prompt: Generate a route for an LLM handling diverse queries\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "LSTM Model Prediction: Legal and Professional Services\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "GRU Model Prediction: Legal and Professional Services\n",
            "BERT Model Prediction: Others\n",
            "Enter a prompt: exit\n"
          ]
        }
      ],
      "source": [
        "user_input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yEbyXVUSyza"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}