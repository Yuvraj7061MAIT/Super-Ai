{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertConfig, BertModel, BertPreTrainedModel\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "xci81sOPqBCI"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Data\n",
        "data = {\n",
        "    'prompt': [\n",
        "        \"Create a chatbot script for customer support\",\n",
        "        \"Generate a response for mental health chat\",\n",
        "        \"Write a conversation starter for virtual assistants\",\n",
        "        \"Generate an image of a sunset over the ocean\",\n",
        "        \"Create a video clip of a relaxing forest scene\",\n",
        "        \"Develop a conversational flow for a virtual assistant handling scheduling\",\n",
        "        \"Generate a supportive message for someone experiencing anxiety\",\n",
        "        \"Write an introduction script for a virtual tour guide\",\n",
        "        \"Create a realistic image of a mountain landscape\",\n",
        "        \"Produce a short video of a cityscape at night\",\n",
        "        \"Compose a background score for a meditation session\",\n",
        "        \"Generate a speech script for a company announcement\",\n",
        "        \"Create podcast episode outlines about technology trends\",\n",
        "        \"Write a blog post on the benefits of remote work\",\n",
        "        \"Generate a podcast script discussing climate change\",\n",
        "        \"Develop a story outline for a children's adventure book\",\n",
        "        \"Create social media posts for a new product launch\",\n",
        "        \"Write product descriptions for an online store\",\n",
        "        \"Optimize a website's content for search engines\",\n",
        "        \"Generate a market analysis report for a new app\",\n",
        "        \"Translate a document from English to Spanish\",\n",
        "        \"Provide coding assistance for a Python project\",\n",
        "        \"Integrate a third-party API into a web application\",\n",
        "        \"Analyze sales data and generate a report\",\n",
        "        \"Create a financial report based on quarterly earnings\",\n",
        "        \"Develop educational content for an online course\",\n",
        "        \"Assist in learning Spanish vocabulary\",\n",
        "        \"Create a PowerPoint presentation on digital marketing\",\n",
        "        \"Generate email templates for business communication\",\n",
        "        \"Draft a legal document for a lease agreement\",\n",
        "        \"Generate a contract for freelance work\",\n",
        "        \"Create a healthy meal plan for a week\",\n",
        "        \"Generate a fitness routine for beginners\",\n",
        "        \"Solve math homework problems\",\n",
        "        \"Detect AI-generated content in student essays\",\n",
        "        \"Design a logo for a startup company\",\n",
        "        \"Create a branding strategy for a new brand\",\n",
        "        \"Plan a travel itinerary for a trip to Europe\",\n",
        "        \"Organize an event plan for a wedding\",\n",
        "        \"Write detailed product descriptions for an online shop\",\n",
        "        \"Generate personalized product recommendations\",\n",
        "        \"Draft a resume for a job application\",\n",
        "        \"Write a cover letter for a software developer position\",\n",
        "        \"Summarize data for a research paper\",\n",
        "        \"Generate a summary of the latest news articles\",\n",
        "        \"Create a news article about a recent scientific discovery\",\n",
        "        \"Generate a route for an LLM handling diverse queries\"\n",
        "    ],\n",
        "    'category': [\n",
        "        \"Communication\",\n",
        "        \"Communication\",\n",
        "        \"Communication\",\n",
        "        \"Visual Art\",\n",
        "        \"Visual Art\",\n",
        "        \"Communication\",\n",
        "        \"Communication\",\n",
        "        \"Communication\",\n",
        "        \"Visual Art\",\n",
        "        \"Visual Art\",\n",
        "        \"Music and Audio\",\n",
        "        \"Music and Audio\",\n",
        "        \"Music and Audio\",\n",
        "        \"Writing and Content Creation\",\n",
        "        \"Writing and Content Creation\",\n",
        "        \"Writing and Content Creation\",\n",
        "        \"Marketing and Advertising\",\n",
        "        \"Marketing and Advertising\",\n",
        "        \"Marketing and Advertising\",\n",
        "        \"Marketing and Advertising\",\n",
        "        \"Translation and Localization\",\n",
        "        \"Programming and Development\",\n",
        "        \"Programming and Development\",\n",
        "        \"Data and Analytics\",\n",
        "        \"Data and Analytics\",\n",
        "        \"Education and Training\",\n",
        "        \"Education and Training\",\n",
        "        \"Business and Productivity\",\n",
        "        \"Business and Productivity\",\n",
        "        \"Legal and Professional Services\",\n",
        "        \"Legal and Professional Services\",\n",
        "        \"Health and Wellness\",\n",
        "        \"Health and Wellness\",\n",
        "        \"Homework\",\n",
        "        \"Homework\",\n",
        "        \"Design\",\n",
        "        \"Design\",\n",
        "        \"Travel and Hospitality\",\n",
        "        \"Travel and Hospitality\",\n",
        "        \"Retail and E-commerce\",\n",
        "        \"Retail and E-commerce\",\n",
        "        \"Human Resources\",\n",
        "        \"Human Resources\",\n",
        "        \"Science and Research\",\n",
        "        \"Science and Research\",\n",
        "        \"Media and Journalism\",\n",
        "        \"Others\"\n",
        "    ],\n",
        "    'subcategory': [\n",
        "        \"Chatbots and Virtual Assistants\",\n",
        "        \"Mental health\",\n",
        "        \"Conversation\",\n",
        "        \"Image Generation\",\n",
        "        \"Video Generation\",\n",
        "        \"Chatbots and Virtual Assistants\",\n",
        "        \"Mental health\",\n",
        "        \"Conversation\",\n",
        "        \"Image Generation\",\n",
        "        \"Video Generation\",\n",
        "        \"Music Creation\",\n",
        "        \"Speech Generation\",\n",
        "        \"Podcast Content Creation\",\n",
        "        \"Blog Writing\",\n",
        "        \"Podcasts\",\n",
        "        \"Storytelling and Narrative Creation\",\n",
        "        \"Social Media Posts\",\n",
        "        \"Product Descriptions\",\n",
        "        \"SEO Optimization\",\n",
        "        \"Market Analysis\",\n",
        "        \"Translation\",\n",
        "        \"Coding and Programming Assistance\",\n",
        "        \"API Integration\",\n",
        "        \"Data Analysis\",\n",
        "        \"Financial Report Generation\",\n",
        "        \"Educational Content Creation\",\n",
        "        \"Language Learning Assistance\",\n",
        "        \"Presentation Creation\",\n",
        "        \"Email Generation\",\n",
        "        \"Legal Document Drafting\",\n",
        "        \"Contract Generation\",\n",
        "        \"Recipe Generation\",\n",
        "        \"Fitness Routine Generation\",\n",
        "        \"Homework Assistance\",\n",
        "        \"AI Content Detection\",\n",
        "        \"Logo Design\",\n",
        "        \"Branding Strategy\",\n",
        "        \"Travel Itinerary Planning\",\n",
        "        \"Event Planning\",\n",
        "        \"Product Description Writing\",\n",
        "        \"Personalized Recommendations\",\n",
        "        \"Resume Drafting\",\n",
        "        \"Cover Letter Writing\",\n",
        "        \"Data Summarization\",\n",
        "        \"News Summary Generation\",\n",
        "        \"News Article Creation\",\n",
        "        \"LLM Route Generation\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "gjxOdM-sqQ95"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "LTyKUkt2qVQd"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['prompt'].values\n",
        "categories = df['category'].values\n",
        "subcategories = df['subcategory'].values"
      ],
      "metadata": {
        "id": "TwdiOr6W_5sN"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization for BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "X_bert = tokenizer(texts.tolist(), padding=True, truncation=True, max_length=50, return_tensors='pt')\n",
        "X_bert_ids = X_bert['input_ids']\n",
        "X_bert_masks = X_bert['attention_mask']"
      ],
      "metadata": {
        "id": "ieJIo4dxAc7z"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_encoder_cat = LabelEncoder()\n",
        "y_cat = label_encoder_cat.fit_transform(categories)\n",
        "\n",
        "label_encoder_subcat = LabelEncoder()\n",
        "y_subcat = label_encoder_subcat.fit_transform(subcategories)"
      ],
      "metadata": {
        "id": "l-NpF8l8AeSW"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train_ids, X_test_ids, y_train_cat, y_test_cat, y_train_subcat, y_test_subcat = train_test_split(\n",
        "    X_bert_ids.numpy(), y_cat, y_subcat, test_size=0.2, random_state=42\n",
        ")\n",
        "X_train_masks, X_test_masks, _, _ = train_test_split(\n",
        "    X_bert_masks.numpy(), X_bert_masks.numpy(), test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "QMSDf4uJAgCc"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Custom Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_masks, category_labels, subcategory_labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.category_labels = category_labels\n",
        "        self.subcategory_labels = subcategory_labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long),\n",
        "            'category_label': torch.tensor(self.category_labels[idx], dtype=torch.long),\n",
        "            'subcategory_label': torch.tensor(self.subcategory_labels[idx], dtype=torch.long)\n",
        "        }\n",
        "        return item"
      ],
      "metadata": {
        "id": "9H8aHeJ5Ajrw"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset instances\n",
        "train_dataset = CustomDataset(\n",
        "    input_ids=X_train_ids.tolist(),\n",
        "    attention_masks=X_train_masks.tolist(),\n",
        "    category_labels=y_train_cat.tolist(),\n",
        "    subcategory_labels=y_train_subcat.tolist()\n",
        ")"
      ],
      "metadata": {
        "id": "EjkgmkjOAlb_"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "q5-xIAmPAnS7"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM model\n",
        "def create_lstm_model(input_length, vocab_size, embedding_dim, num_labels):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),\n",
        "        LSTM(128),\n",
        "        Dense(num_labels, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "BCLxBPCNAqSl"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare LSTM data\n",
        "max_length = 50\n",
        "X_bert_padded = pad_sequences(X_bert_ids.numpy(), maxlen=max_length)\n",
        "vocab_size = tokenizer.vocab_size\n",
        "embedding_dim = 50"
      ],
      "metadata": {
        "id": "vMbrsXQpArGR"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LSTM model\n",
        "lstm_model = create_lstm_model(max_length, vocab_size, embedding_dim, len(label_encoder_cat.classes_))\n",
        "history_lstm = lstm_model.fit(\n",
        "    X_bert_padded, y_cat,\n",
        "    epochs=100,\n",
        "    batch_size=8,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM0qg-FWAs7t",
        "outputId": "33482945-6410-4f0f-b49f-a5407a9ed0de"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 190ms/step - accuracy: 0.0252 - loss: 2.9966 - val_accuracy: 0.0000e+00 - val_loss: 3.0284\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.1292 - loss: 2.9727 - val_accuracy: 0.0000e+00 - val_loss: 3.0850\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.2081 - loss: 2.9399 - val_accuracy: 0.0000e+00 - val_loss: 3.2839\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 111ms/step - accuracy: 0.1325 - loss: 2.8803 - val_accuracy: 0.0000e+00 - val_loss: 4.4321\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.1783 - loss: 2.8146 - val_accuracy: 0.0000e+00 - val_loss: 4.9220\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.1024 - loss: 2.8225 - val_accuracy: 0.0000e+00 - val_loss: 4.2863\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.1337 - loss: 2.7397 - val_accuracy: 0.0000e+00 - val_loss: 4.3027\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.1381 - loss: 2.7630 - val_accuracy: 0.0000e+00 - val_loss: 4.7028\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.1366 - loss: 2.7842 - val_accuracy: 0.0000e+00 - val_loss: 5.1981\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0876 - loss: 2.7415 - val_accuracy: 0.0000e+00 - val_loss: 5.5706\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.0906 - loss: 2.6528 - val_accuracy: 0.0000e+00 - val_loss: 5.3112\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.1197 - loss: 2.6853 - val_accuracy: 0.0000e+00 - val_loss: 5.0267\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2460 - loss: 2.6018 - val_accuracy: 0.0000e+00 - val_loss: 4.7524\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.1345 - loss: 2.7315 - val_accuracy: 0.0000e+00 - val_loss: 4.6682\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.1753 - loss: 2.6094 - val_accuracy: 0.0000e+00 - val_loss: 5.3584\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.1530 - loss: 2.5596 - val_accuracy: 0.0000e+00 - val_loss: 5.2545\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.2356 - loss: 2.4467 - val_accuracy: 0.0000e+00 - val_loss: 4.8095\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.1857 - loss: 2.4746 - val_accuracy: 0.0000e+00 - val_loss: 5.1443\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.2154 - loss: 2.3765 - val_accuracy: 0.0000e+00 - val_loss: 4.8930\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3321 - loss: 2.1997 - val_accuracy: 0.0000e+00 - val_loss: 5.7531\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3089 - loss: 2.1020 - val_accuracy: 0.0000e+00 - val_loss: 5.7287\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.3871 - loss: 1.9656 - val_accuracy: 0.0000e+00 - val_loss: 5.4369\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5721 - loss: 1.6701 - val_accuracy: 0.0000e+00 - val_loss: 6.2969\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4206 - loss: 1.6154 - val_accuracy: 0.0000e+00 - val_loss: 6.1546\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.4137 - loss: 1.6616 - val_accuracy: 0.0000e+00 - val_loss: 8.1440\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6165 - loss: 1.3304 - val_accuracy: 0.0000e+00 - val_loss: 6.4619\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5832 - loss: 1.2545 - val_accuracy: 0.0000e+00 - val_loss: 7.6173\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.7377 - loss: 1.0393 - val_accuracy: 0.0000e+00 - val_loss: 9.5113\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.6910 - loss: 0.9603 - val_accuracy: 0.0000e+00 - val_loss: 8.6621\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.6842 - loss: 0.9706 - val_accuracy: 0.0000e+00 - val_loss: 7.9209\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.6568 - loss: 0.8676 - val_accuracy: 0.0000e+00 - val_loss: 8.7484\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7785 - loss: 0.8085 - val_accuracy: 0.0000e+00 - val_loss: 10.3368\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9540 - loss: 0.4953 - val_accuracy: 0.0000e+00 - val_loss: 9.4263\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8887 - loss: 0.4764 - val_accuracy: 0.0000e+00 - val_loss: 10.7100\n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9495 - loss: 0.3787 - val_accuracy: 0.0000e+00 - val_loss: 9.3600\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9495 - loss: 0.4119 - val_accuracy: 0.0000e+00 - val_loss: 10.2586\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9227 - loss: 0.3363 - val_accuracy: 0.0000e+00 - val_loss: 10.7920\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9852 - loss: 0.2554 - val_accuracy: 0.0000e+00 - val_loss: 8.3476\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9792 - loss: 0.2070 - val_accuracy: 0.0000e+00 - val_loss: 12.0311\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9079 - loss: 0.2481 - val_accuracy: 0.0000e+00 - val_loss: 9.0943\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9703 - loss: 0.2667 - val_accuracy: 0.0000e+00 - val_loss: 9.6668\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9703 - loss: 0.1934 - val_accuracy: 0.0000e+00 - val_loss: 11.3178\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9495 - loss: 0.1682 - val_accuracy: 0.0000e+00 - val_loss: 10.3050\n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9852 - loss: 0.2034 - val_accuracy: 0.0000e+00 - val_loss: 7.9667\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.2206 - val_accuracy: 0.0000e+00 - val_loss: 11.1587\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9703 - loss: 0.1417 - val_accuracy: 0.0000e+00 - val_loss: 11.9006\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.1172 - val_accuracy: 0.0000e+00 - val_loss: 11.4854\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0899 - val_accuracy: 0.0000e+00 - val_loss: 10.6221\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0590 - val_accuracy: 0.0000e+00 - val_loss: 10.2606\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0481 - val_accuracy: 0.0000e+00 - val_loss: 10.6498\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0421 - val_accuracy: 0.0000e+00 - val_loss: 10.9097\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0400 - val_accuracy: 0.0000e+00 - val_loss: 10.9490\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0341 - val_accuracy: 0.0000e+00 - val_loss: 10.8889\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 1.0000 - loss: 0.0375 - val_accuracy: 0.0000e+00 - val_loss: 10.8154\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0311 - val_accuracy: 0.0000e+00 - val_loss: 10.8164\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 0.0000e+00 - val_loss: 10.8848\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.0000e+00 - val_loss: 10.9565\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.0000e+00 - val_loss: 10.9802\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0230 - val_accuracy: 0.0000e+00 - val_loss: 10.9223\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0212 - val_accuracy: 0.0000e+00 - val_loss: 10.9509\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.0000e+00 - val_loss: 10.9909\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.0000e+00 - val_loss: 11.0388\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0164 - val_accuracy: 0.0000e+00 - val_loss: 10.9772\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.0000e+00 - val_loss: 10.9707\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.0000e+00 - val_loss: 10.9492\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.0000e+00 - val_loss: 10.9879\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.0000e+00 - val_loss: 11.0051\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0151 - val_accuracy: 0.0000e+00 - val_loss: 10.9559\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.0000e+00 - val_loss: 10.9921\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.0000e+00 - val_loss: 11.0011\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.0000e+00 - val_loss: 11.0288\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.0000e+00 - val_loss: 11.0551\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.0000e+00 - val_loss: 11.0507\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.0000e+00 - val_loss: 11.0554\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.0000e+00 - val_loss: 11.0800\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.0000e+00 - val_loss: 11.0791\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.0000e+00 - val_loss: 11.1291\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.0000e+00 - val_loss: 11.1187\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.0000e+00 - val_loss: 11.1001\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.0000e+00 - val_loss: 11.0313\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.0000e+00 - val_loss: 11.0288\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.0000e+00 - val_loss: 11.1304\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.0000e+00 - val_loss: 11.1677\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.0000e+00 - val_loss: 11.1613\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.0000e+00 - val_loss: 11.1133\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.0000e+00 - val_loss: 11.0961\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.0000e+00 - val_loss: 11.1135\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.0000e+00 - val_loss: 11.1589\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0075 - val_accuracy: 0.0000e+00 - val_loss: 11.1330\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.0000e+00 - val_loss: 11.1520\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.0000e+00 - val_loss: 11.1883\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.0000e+00 - val_loss: 11.1813\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.0000e+00 - val_loss: 11.1202\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 10.9890\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 11.0174\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 11.0762\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.0000e+00 - val_loss: 11.1241\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.0000e+00 - val_loss: 11.1547\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.0000e+00 - val_loss: 11.1388\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.0000e+00 - val_loss: 11.1211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GRU model\n",
        "def create_gru_model(input_length, vocab_size, embedding_dim, num_labels):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),\n",
        "        GRU(128),\n",
        "        Dense(num_labels, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "IixvtI_nAugX"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train GRU model\n",
        "gru_model = create_gru_model(max_length, vocab_size, embedding_dim, len(label_encoder_cat.classes_))\n",
        "history_gru = gru_model.fit(\n",
        "    X_bert_padded, y_cat,\n",
        "    epochs=100,\n",
        "    batch_size=8,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIbyeZawAwdu",
        "outputId": "a1ed5f6d-07c6-4ccc-f8e9-494583524fcc"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 178ms/step - accuracy: 0.0832 - loss: 2.9959 - val_accuracy: 0.0000e+00 - val_loss: 3.0301\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.1099 - loss: 2.9722 - val_accuracy: 0.0000e+00 - val_loss: 3.0765\n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.1619 - loss: 2.9438 - val_accuracy: 0.0000e+00 - val_loss: 3.1381\n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.1500 - loss: 2.9222 - val_accuracy: 0.0000e+00 - val_loss: 3.2301\n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.1233 - loss: 2.8926 - val_accuracy: 0.0000e+00 - val_loss: 3.3798\n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.1203 - loss: 2.8657 - val_accuracy: 0.0000e+00 - val_loss: 3.6905\n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2081 - loss: 2.7457 - val_accuracy: 0.0000e+00 - val_loss: 4.1091\n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.1426 - loss: 2.8094 - val_accuracy: 0.0000e+00 - val_loss: 3.8719\n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1009 - loss: 2.7756 - val_accuracy: 0.0000e+00 - val_loss: 4.0873\n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.0875 - loss: 2.7551 - val_accuracy: 0.0000e+00 - val_loss: 4.4248\n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1679 - loss: 2.6604 - val_accuracy: 0.0000e+00 - val_loss: 4.7715\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.1396 - loss: 2.6818 - val_accuracy: 0.0000e+00 - val_loss: 4.8213\n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.1108 - loss: 2.7897 - val_accuracy: 0.0000e+00 - val_loss: 4.4674\n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.1337 - loss: 2.6438 - val_accuracy: 0.0000e+00 - val_loss: 5.7820\n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.1524 - loss: 2.5671 - val_accuracy: 0.0000e+00 - val_loss: 4.7102\n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1722 - loss: 2.5525 - val_accuracy: 0.0000e+00 - val_loss: 4.9074\n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1955 - loss: 2.4069 - val_accuracy: 0.0000e+00 - val_loss: 5.7204\n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1887 - loss: 2.1235 - val_accuracy: 0.0000e+00 - val_loss: 4.3669\n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.2733 - loss: 2.2619 - val_accuracy: 0.0000e+00 - val_loss: 4.5471\n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4144 - loss: 2.0173 - val_accuracy: 0.0000e+00 - val_loss: 9.3513\n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.3430 - loss: 1.9879 - val_accuracy: 0.0000e+00 - val_loss: 4.8587\n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.6033 - loss: 1.5294 - val_accuracy: 0.0000e+00 - val_loss: 6.6655\n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.4727 - loss: 1.6318 - val_accuracy: 0.0000e+00 - val_loss: 8.2377\n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.4122 - loss: 1.5331 - val_accuracy: 0.0000e+00 - val_loss: 5.7555\n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6115 - loss: 1.1862 - val_accuracy: 0.0000e+00 - val_loss: 6.2941\n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.6151 - loss: 1.1734 - val_accuracy: 0.0000e+00 - val_loss: 7.2223\n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.6412 - loss: 1.1322 - val_accuracy: 0.0000e+00 - val_loss: 8.3433\n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5676 - loss: 1.0721 - val_accuracy: 0.0000e+00 - val_loss: 9.1412\n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.6893 - loss: 1.0320 - val_accuracy: 0.0000e+00 - val_loss: 10.0069\n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.6567 - loss: 0.9454 - val_accuracy: 0.0000e+00 - val_loss: 10.0219\n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.7452 - loss: 0.7513 - val_accuracy: 0.0000e+00 - val_loss: 10.5002\n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.7502 - loss: 0.9164 - val_accuracy: 0.0000e+00 - val_loss: 7.8347\n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6836 - loss: 0.9135 - val_accuracy: 0.0000e+00 - val_loss: 9.5133\n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.8396 - loss: 0.8017 - val_accuracy: 0.0000e+00 - val_loss: 10.8325\n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7549 - loss: 0.8103 - val_accuracy: 0.0000e+00 - val_loss: 10.1012\n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9159 - loss: 0.7103 - val_accuracy: 0.0000e+00 - val_loss: 9.0359\n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9451 - loss: 0.5775 - val_accuracy: 0.0000e+00 - val_loss: 9.5600\n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8648 - loss: 0.5382 - val_accuracy: 0.0000e+00 - val_loss: 10.5479\n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8640 - loss: 0.5444 - val_accuracy: 0.0000e+00 - val_loss: 10.7737\n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9064 - loss: 0.4799 - val_accuracy: 0.0000e+00 - val_loss: 10.9831\n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9406 - loss: 0.4007 - val_accuracy: 0.0000e+00 - val_loss: 11.0907\n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9213 - loss: 0.3989 - val_accuracy: 0.0000e+00 - val_loss: 11.6256\n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9272 - loss: 0.3442 - val_accuracy: 0.0000e+00 - val_loss: 11.9299\n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 0.9391 - loss: 0.2930 - val_accuracy: 0.0000e+00 - val_loss: 11.9687\n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9347 - loss: 0.2320 - val_accuracy: 0.0000e+00 - val_loss: 12.0712\n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.9585 - loss: 0.2044 - val_accuracy: 0.0000e+00 - val_loss: 11.9256\n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9828 - loss: 0.1605 - val_accuracy: 0.0000e+00 - val_loss: 12.2594\n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9792 - loss: 0.1995 - val_accuracy: 0.0000e+00 - val_loss: 12.1996\n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.1965 - val_accuracy: 0.0000e+00 - val_loss: 11.5071\n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1982 - val_accuracy: 0.0000e+00 - val_loss: 12.0066\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.9524 - loss: 0.1735 - val_accuracy: 0.0000e+00 - val_loss: 12.3174\n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1258 - val_accuracy: 0.0000e+00 - val_loss: 12.4317\n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.1352 - val_accuracy: 0.0000e+00 - val_loss: 12.4744\n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.1293 - val_accuracy: 0.0000e+00 - val_loss: 12.2727\n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0938 - val_accuracy: 0.0000e+00 - val_loss: 12.4069\n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0791 - val_accuracy: 0.0000e+00 - val_loss: 12.3110\n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0810 - val_accuracy: 0.0000e+00 - val_loss: 12.2680\n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0776 - val_accuracy: 0.0000e+00 - val_loss: 12.5846\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0698 - val_accuracy: 0.0000e+00 - val_loss: 12.4911\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0618 - val_accuracy: 0.0000e+00 - val_loss: 12.2678\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0574 - val_accuracy: 0.0000e+00 - val_loss: 12.6705\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0497 - val_accuracy: 0.0000e+00 - val_loss: 12.7962\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0467 - val_accuracy: 0.0000e+00 - val_loss: 12.5859\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0374 - val_accuracy: 0.0000e+00 - val_loss: 12.6137\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0494 - val_accuracy: 0.0000e+00 - val_loss: 12.8506\n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0375 - val_accuracy: 0.0000e+00 - val_loss: 12.6595\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0380 - val_accuracy: 0.0000e+00 - val_loss: 12.4778\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0351 - val_accuracy: 0.0000e+00 - val_loss: 12.6205\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0341 - val_accuracy: 0.0000e+00 - val_loss: 12.7879\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0327 - val_accuracy: 0.0000e+00 - val_loss: 12.7482\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 1.0000 - loss: 0.0283 - val_accuracy: 0.0000e+00 - val_loss: 12.6994\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0279 - val_accuracy: 0.0000e+00 - val_loss: 12.7124\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.0000e+00 - val_loss: 12.7314\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0284 - val_accuracy: 0.0000e+00 - val_loss: 12.7503\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0242 - val_accuracy: 0.0000e+00 - val_loss: 12.7509\n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.0000e+00 - val_loss: 12.7882\n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.0000e+00 - val_loss: 12.8050\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 0.0000e+00 - val_loss: 12.7997\n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0214 - val_accuracy: 0.0000e+00 - val_loss: 12.8115\n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0208 - val_accuracy: 0.0000e+00 - val_loss: 12.8324\n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.0000e+00 - val_loss: 12.8477\n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.0000e+00 - val_loss: 12.8696\n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.0000e+00 - val_loss: 12.8907\n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.0000e+00 - val_loss: 12.9063\n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.0000e+00 - val_loss: 12.9206\n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.0000e+00 - val_loss: 12.9297\n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0173 - val_accuracy: 0.0000e+00 - val_loss: 12.9407\n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.0000e+00 - val_loss: 12.9427\n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.0000e+00 - val_loss: 12.9585\n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.0000e+00 - val_loss: 12.9614\n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.0000e+00 - val_loss: 12.9586\n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.0000e+00 - val_loss: 12.9724\n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0161 - val_accuracy: 0.0000e+00 - val_loss: 12.9883\n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.0000e+00 - val_loss: 12.9967\n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.0000e+00 - val_loss: 13.0044\n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.0000e+00 - val_loss: 13.0195\n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.0000e+00 - val_loss: 13.0182\n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0113 - val_accuracy: 0.0000e+00 - val_loss: 13.0382\n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.0000e+00 - val_loss: 13.0529\n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0130 - val_accuracy: 0.0000e+00 - val_loss: 13.0669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define BERT model\n",
        "class BertForTextClassification(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(config.hidden_size, len(label_encoder_cat.classes_))\n",
        "        self.subclassifier = nn.Linear(config.hidden_size, len(label_encoder_subcat.classes_))\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        sub_logits = self.subclassifier(pooled_output)\n",
        "        return logits, sub_logits"
      ],
      "metadata": {
        "id": "LtV_4xUSAzEZ"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train BERT model\n",
        "config = BertConfig.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertForTextClassification(config)"
      ],
      "metadata": {
        "id": "QiYfRIr3A1kG"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(bert_model.parameters(), lr=1e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cI96nT2VA3cm"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop for BERT\n",
        "bert_model.train()\n",
        "for epoch in range(50):\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        category_labels = batch['category_label']\n",
        "        subcategory_labels = batch['subcategory_label']\n",
        "\n",
        "        logits, sub_logits = bert_model(input_ids, attention_mask=attention_mask)\n",
        "        loss_cat = loss_fn(logits, category_labels)\n",
        "        loss_subcat = loss_fn(sub_logits, subcategory_labels)\n",
        "        loss = loss_cat + loss_subcat\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}: Loss = {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrhkp_wA42S",
        "outputId": "c058d14f-5f33-4cee-8950-d052c054f370"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 6.735448837280273\n",
            "Epoch 2: Loss = 6.722023963928223\n",
            "Epoch 3: Loss = 6.733700752258301\n",
            "Epoch 4: Loss = 6.648200035095215\n",
            "Epoch 5: Loss = 6.283683776855469\n",
            "Epoch 6: Loss = 5.719743728637695\n",
            "Epoch 7: Loss = 6.4594268798828125\n",
            "Epoch 8: Loss = 5.639106750488281\n",
            "Epoch 9: Loss = 6.060833930969238\n",
            "Epoch 10: Loss = 5.759893417358398\n",
            "Epoch 11: Loss = 5.970782279968262\n",
            "Epoch 12: Loss = 5.234567642211914\n",
            "Epoch 13: Loss = 5.895871639251709\n",
            "Epoch 14: Loss = 5.5872697830200195\n",
            "Epoch 15: Loss = 5.972634315490723\n",
            "Epoch 16: Loss = 5.353873252868652\n",
            "Epoch 17: Loss = 5.580223083496094\n",
            "Epoch 18: Loss = 5.456847190856934\n",
            "Epoch 19: Loss = 4.879000663757324\n",
            "Epoch 20: Loss = 4.1474409103393555\n",
            "Epoch 21: Loss = 3.846884250640869\n",
            "Epoch 22: Loss = 4.843586444854736\n",
            "Epoch 23: Loss = 3.8165626525878906\n",
            "Epoch 24: Loss = 3.9803788661956787\n",
            "Epoch 25: Loss = 4.0972514152526855\n",
            "Epoch 26: Loss = 2.983478546142578\n",
            "Epoch 27: Loss = 3.6032981872558594\n",
            "Epoch 28: Loss = 3.2951605319976807\n",
            "Epoch 29: Loss = 3.139699697494507\n",
            "Epoch 30: Loss = 2.3752105236053467\n",
            "Epoch 31: Loss = 2.3973336219787598\n",
            "Epoch 32: Loss = 2.6454415321350098\n",
            "Epoch 33: Loss = 2.166926383972168\n",
            "Epoch 34: Loss = 2.5096142292022705\n",
            "Epoch 35: Loss = 2.291612148284912\n",
            "Epoch 36: Loss = 1.6293293237686157\n",
            "Epoch 37: Loss = 1.6123549938201904\n",
            "Epoch 38: Loss = 2.008284330368042\n",
            "Epoch 39: Loss = 1.8672059774398804\n",
            "Epoch 40: Loss = 1.6538081169128418\n",
            "Epoch 41: Loss = 1.650434970855713\n",
            "Epoch 42: Loss = 1.5619369745254517\n",
            "Epoch 43: Loss = 1.4867088794708252\n",
            "Epoch 44: Loss = 1.2910194396972656\n",
            "Epoch 45: Loss = 1.1319915056228638\n",
            "Epoch 46: Loss = 1.3321529626846313\n",
            "Epoch 47: Loss = 1.3427058458328247\n",
            "Epoch 48: Loss = 1.3764050006866455\n",
            "Epoch 49: Loss = 1.1415923833847046\n",
            "Epoch 50: Loss = 1.393474817276001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict using all models separately\n",
        "def predict_separate_models(texts):\n",
        "    # Prepare input for BERT\n",
        "    bert_inputs = tokenizer(texts, padding=True, truncation=True, max_length=50, return_tensors='pt')\n",
        "    input_ids = bert_inputs['input_ids'].clone().detach()\n",
        "    attention_mask = bert_inputs['attention_mask'].clone().detach()\n",
        "\n",
        "    # Predict with LSTM\n",
        "    X_bert_padded_test = pad_sequences(tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors='pt')['input_ids'].numpy(), maxlen=max_length)\n",
        "    lstm_preds = lstm_model.predict(X_bert_padded_test)\n",
        "\n",
        "    # Predict with GRU\n",
        "    gru_preds = gru_model.predict(X_bert_padded_test)\n",
        "\n",
        "    # Predict with BERT\n",
        "    with torch.no_grad():\n",
        "        logits, sub_logits = bert_model(input_ids, attention_mask=attention_mask)\n",
        "        bert_preds_cat = torch.argmax(logits, dim=1).numpy()\n",
        "        bert_preds_subcat = torch.argmax(sub_logits, dim=1).numpy()\n",
        "\n",
        "    # Return predictions separately\n",
        "    return lstm_preds, gru_preds, bert_preds_cat, bert_preds_subcat"
      ],
      "metadata": {
        "id": "szgiHbcNA666"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using all models\n",
        "texts_to_predict = [\"Plan a travel itinerary for a trip to Europe\"]\n",
        "lstm_preds, gru_preds, bert_preds_cat, bert_preds_subcat = predict_separate_models(texts_to_predict)\n",
        "\n",
        "# Convert predictions to category and subcategory labels\n",
        "lstm_categories = np.argmax(lstm_preds, axis=1)\n",
        "gru_categories = np.argmax(gru_preds, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76D-z5LEBLTB",
        "outputId": "7d406544-9d3c-4e99-e9f2-3a5ef32a2fc6"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"LSTM Predicted Categories: {label_encoder_cat.inverse_transform(lstm_categories)}\")\n",
        "print(f\"LSTM Predicted Subcategories: {label_encoder_subcat.inverse_transform(np.argmax(lstm_preds, axis=1))}\")\n",
        "\n",
        "print(f\"GRU Predicted Categories: {label_encoder_cat.inverse_transform(np.argmax(gru_preds, axis=1))}\")\n",
        "print(f\"GRU Predicted Subcategories: {label_encoder_subcat.inverse_transform(np.argmax(gru_preds, axis=1))}\")\n",
        "\n",
        "print(f\"BERT Predicted Categories: {label_encoder_cat.inverse_transform(bert_preds_cat)}\")\n",
        "print(f\"BERT Predicted Subcategories: {label_encoder_subcat.inverse_transform(bert_preds_subcat)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIAjqvmABQHf",
        "outputId": "5244a548-ee82-441d-c673-45e8ff31cdef"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM Predicted Categories: ['Travel and Hospitality']\n",
            "LSTM Predicted Subcategories: ['Image Generation']\n",
            "GRU Predicted Categories: ['Travel and Hospitality']\n",
            "GRU Predicted Subcategories: ['Image Generation']\n",
            "BERT Predicted Categories: ['Travel and Hospitality']\n",
            "BERT Predicted Subcategories: ['Travel Itinerary Planning']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hgh-yIBtCG9-"
      },
      "execution_count": 139,
      "outputs": []
    }
  ]
}