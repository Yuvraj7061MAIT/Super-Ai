{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "GqglF0s1n5xy"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/assignment/prompts_classification_data.csv')"
      ],
      "metadata": {
        "id": "Bq4c7QgJnoZL"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "label_mapping = {label: idx for idx, label in enumerate(df['category'].unique())}\n",
        "df['label'] = df['category'].map(label_mapping)"
      ],
      "metadata": {
        "id": "ipXE0dnxsUvr"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df['prompt'], df['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "T7Vt6H_1uRtC"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "4HO588bZuTnI"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize data\n",
        "def tokenize_data(texts):\n",
        "    return tokenizer(texts.tolist(), truncation=True, padding=True, max_length=128, return_tensors='pt')\n",
        "\n",
        "train_encodings = tokenize_data(train_texts)\n",
        "test_encodings = tokenize_data(test_texts)"
      ],
      "metadata": {
        "id": "T9Ph1zxMuiKW"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset class\n",
        "class PromptDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels.iloc[idx]).clone().detach()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "6UmCBPNBujWW"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = PromptDataset(train_encodings, train_labels)\n",
        "test_dataset = PromptDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "GwXYjjKnulJ-"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_mapping))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRMFTe_eumpU",
        "outputId": "357cc409-9bcc-4816-d734-d20840e2c6f9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")"
      ],
      "metadata": {
        "id": "lTmvBcF7ursn"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "3O3kwNODuu6i"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "m8cKBRe2uyCE",
        "outputId": "d795a102-6352-44da-b801-4b96d54935f0"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-113-07cd8e96a4b9>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [30/30 00:10, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=30, training_loss=3.7153722127278646, metrics={'train_runtime': 10.2925, 'train_samples_per_second': 33.034, 'train_steps_per_second': 2.915, 'total_flos': 2971263898440.0, 'train_loss': 3.7153722127278646, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "test_preds = trainer.predict(test_dataset)\n",
        "pred_labels = torch.argmax(torch.tensor(test_preds.predictions), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "nA_8Qv-ruzLz",
        "outputId": "e2d4ec40-501a-436c-99c7-0aca281fc735"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-113-07cd8e96a4b9>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to lists\n",
        "test_labels_list = test_labels.tolist()\n",
        "pred_labels_list = pred_labels.tolist()"
      ],
      "metadata": {
        "id": "2_GIqx_Ku1jR"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(test_labels_list, pred_labels_list)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyn8eiPku3VW",
        "outputId": "3ac471b6-2b54-4f1e-be0d-22b50369e6ef"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the unique classes from the test labels and predictions\n",
        "unique_labels = sorted(set(test_labels_list + pred_labels_list))\n",
        "target_names = [label for label, idx in sorted(label_mapping.items(), key=lambda item: item[1]) if idx in unique_labels]\n"
      ],
      "metadata": {
        "id": "U5HA6WSPu46D"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels_list, pred_labels_list, labels=unique_labels, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymjwWPCuu6k0",
        "outputId": "20fb321c-1046-4a48-dd05-5c9c17e5ade6"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "                                 precision    recall  f1-score   support\n",
            "\n",
            "               Video Generation       0.00      0.00      0.00       1.0\n",
            "                   Blog Writing       0.00      0.00      0.00       1.0\n",
            "           Product Descriptions       0.00      0.00      0.00       2.0\n",
            "                API Integration       0.00      0.00      0.00       0.0\n",
            "        Legal Document Drafting       0.00      0.00      0.00       1.0\n",
            "            Contract Generation       0.00      0.00      0.00       1.0\n",
            "Resume and Cover Letter Writing       0.00      0.00      0.00       1.0\n",
            "       Job Description Creation       0.00      0.00      0.00       1.0\n",
            "                 Summarisations       0.00      0.00      0.00       1.0\n",
            "          Content Summarization       0.00      0.00      0.00       0.0\n",
            "\n",
            "                       accuracy                           0.00       9.0\n",
            "                      macro avg       0.00      0.00      0.00       9.0\n",
            "                   weighted avg       0.00      0.00      0.00       9.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MzV0-yLHvGEd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}